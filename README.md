# Adverse Reactions Entity Extraction
Information Retrieval & Text Mining project

This project used a gold standard annotated dataset of adverse events and their modifiers found in structured product labels. Preprocessing and data formatting steps were executed such as parsing different file formats (xml, txt, and ann) and tokenizing both on a word and sentence level (including IOB tagging). The main task was entity extraction to find the many different possible adverse events. An implementation of LSTM-CRF performed quite poorly, probably due to a lack of data. Conditional random fields on their own performed very well, especially with an expansive hand-crafted feature factory taking into account the tokens and their context. In particular, certain suffixes or preceding words were very useful. The CRF had an F1-score of 0.87 for finding adverse reactions. A huge advantage of CRFs are their transparency. Thirdly, the bidirectional LSTM BERT was used. We augmented the data to provide a larger dataset by searching for all the synonyms of the training set. This augmented dataset was given to BioBERT, which performed exceedingly well with an F1-score of 0.95. BERT outperformed the CRF, but at the cost of higher computational resources and a loss of transparency. Negation was handled by dependency grammars and co-references with a pre-trained neural net. Finally, the data was represented in a number of ways such as wordclouds, chord diagrams, drug specific human body diagrams, and through a sunburst.

Over half of Americans use prescription drugs and structured product labels are among the best documentation about their known adverse events. Unfortunately, due to the fact that the information is buried in free text sections, it is under utilized \cite{kilicoglu2014coreference}. According to the overview of the TAC 2017 competition, the highest F1-score for finding the adverse reactions was of 85.2. It may be noted that they only received the 101 training set and their score came from the 99 test set \cite{roberts2017overview}. We combined both datasets to have more annotations and used a 90-10\% training-test split. Furthermore, the first paper about BERT only came out in late 2018. Nonetheless, our results vastly outperform theirs with 87\% for the CRF and 95\% for BioBERT. This project contributes to automatically extracting and visualizing drug adverse events through text mining.
